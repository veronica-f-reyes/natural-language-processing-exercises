{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2881202",
   "metadata": {},
   "source": [
    "# Data Preparation Exercises\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5e4eb",
   "metadata": {},
   "source": [
    "### In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa8361",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "    - Lowercase everything\n",
    "    - Normalize unicode characters\n",
    "    - Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e41ea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/vfirey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ce92bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Codeup’s Data Science Career Accelerator is Here!   \n",
      "1                                 Data Science Myths   \n",
      "2  Data Science VS Data Analytics: What’s The Dif...   \n",
      "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
      "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
      "\n",
      "                                             content  \n",
      "0  The rumors are true! The time has arrived. Cod...  \n",
      "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
      "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
      "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
      "4  Competitor Bootcamps Are Closing. Is the Model...  \n"
     ]
    }
   ],
   "source": [
    "original = acquire.get_blog_articles()\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084662a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \n",
    "    # This function does basic cleaning and prepping of a string\n",
    "    \n",
    "    #Lowercase all text in string\n",
    "    prepped_string = string.lower()   \n",
    "    \n",
    "    #Normalize unicode letters\n",
    "    prepped_string = unicodedata.normalize('NFKD', prepped_string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore') \n",
    "    \n",
    "    # remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "    prepped_string = re.sub(r\"[^a-z0-9'\\s]\", '', prepped_string)\n",
    "\n",
    "    return prepped_string\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea97d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0    the rumors are true the time has arrived cod\\n1    by dimitri antoniou and maggie giustndata sci\\n2    by dimitri antoniouna week ago codeup launch\\n3    sa tech job fairnthe third biannual san anto\\n4    competitor bootcamps are closing is the model\\nname content dtype object'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(str(original.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23f9e5",
   "metadata": {},
   "source": [
    "#### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8696ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    \n",
    "    #Import libraries\n",
    "    import nltk\n",
    "    from nltk.tokenize.toktok import ToktokTokenizer\n",
    "    \n",
    "    #This function takes in a string and tokenizes all the words in the string.\n",
    "    \n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    return (tokenizer.tokenize(string, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a8bdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 The rumors are true ! The time has arrived. Cod ... \\n1 By Dimitri Antoniou and Maggie Giust\\\\nData Sci ... \\n2 By Dimitri Antoniou\\\\nA week ago , Codeup launch ... \\n3 SA Tech Job Fair\\\\nThe third bi-annual San Anto ... \\n4 Competitor Bootcamps Are Closing. Is the Model ... \\nName : content , dtype : object'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(str(original.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30953d87",
   "metadata": {},
   "source": [
    "#### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b5fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    \n",
    "    #Import library\n",
    "    import nltk\n",
    "    \n",
    "    # This function accepts some text and returns the text after applying stemming to all the words.\n",
    "    \n",
    "    # Create the nltk stemmer object, then use it\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    stems = [ps.stem(word) for word in text.split()]\n",
    "    text_stemmed = ' '.join(stems)\n",
    "    \n",
    "    return text_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ad8830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 the rumor are true! the time ha arrived. cod... 1 by dimitri antoni and maggi giust\\\\ndata sci... 2 by dimitri antoniou\\\\na week ago, codeup launch... 3 sa tech job fair\\\\nth third bi-annu san anto... 4 competitor bootcamp are closing. is the model... name: content, dtype: object'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(str(original.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdf9ae",
   "metadata": {},
   "source": [
    "#### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4934adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    \n",
    "    #This function accepts some text and returns the text after applying lemmatization to each word.\n",
    "    \n",
    "    # Create the nltk lemmatizer object, then use it\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    text_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "    return text_lemmatized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ec8ce8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 The rumor are true! The time ha arrived. Cod... 1 By Dimitri Antoniou and Maggie Giust\\\\nData Sci... 2 By Dimitri Antoniou\\\\nA week ago, Codeup launch... 3 SA Tech Job Fair\\\\nThe third bi-annual San Anto... 4 Competitor Bootcamps Are Closing. Is the Model... Name: content, dtype: object'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(str(original.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd4f04",
   "metadata": {},
   "source": [
    "#### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    " This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "928f94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467b6ee",
   "metadata": {},
   "source": [
    "#### 6.) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1684240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rumor true time ha arrived codeup ha officiall...\n",
       "1    dimitri antoniou maggie giust data science big...\n",
       "2    dimitri antoniou week ago codeup launched imme...\n",
       "3    sa tech job fair third biannual san antonio te...\n",
       "4    competitor bootcamps closing model danger prog...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use all the functions to see if they work on the content column\n",
    "original['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1136af4",
   "metadata": {},
   "source": [
    "#### 7.) Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "014416f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = strftime('%Y-%m-%d')\n",
    "codeup_df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db74eb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dec79",
   "metadata": {},
   "source": [
    "#### 8.) For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f65d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f443aab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "      <td>rumors true time arrived codeup officially ope...</td>\n",
       "      <td>rumor true time arriv codeup offici open appli...</td>\n",
       "      <td>rumor true time arrived codeup officially open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "      <td>dimitri antoniou maggie giust data science big...</td>\n",
       "      <td>dimitri antoni maggi giust data scienc big dat...</td>\n",
       "      <td>dimitri antoniou maggie giust data science big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "      <td>dimitri antoniou week ago codeup launched imme...</td>\n",
       "      <td>dimitri antoni week ago codeup launch immers d...</td>\n",
       "      <td>dimitri antoniou week ago codeup launched imme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "      <td>sa tech job fair third biannual san antonio te...</td>\n",
       "      <td>sa tech job fair third biannual san antonio te...</td>\n",
       "      <td>sa tech job fair third biannual san antonio te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>competitor bootcamps closing model danger prog...</td>\n",
       "      <td>competitor bootcamp close model danger program...</td>\n",
       "      <td>competitor bootcamps closing model danger prog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The rumors are true! The time has arrived. Cod...   \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...   \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...   \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  rumors true time arrived codeup officially ope...   \n",
       "1  dimitri antoniou maggie giust data science big...   \n",
       "2  dimitri antoniou week ago codeup launched imme...   \n",
       "3  sa tech job fair third biannual san antonio te...   \n",
       "4  competitor bootcamps closing model danger prog...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  rumor true time arriv codeup offici open appli...   \n",
       "1  dimitri antoni maggi giust data scienc big dat...   \n",
       "2  dimitri antoni week ago codeup launch immers d...   \n",
       "3  sa tech job fair third biannual san antonio te...   \n",
       "4  competitor bootcamp close model danger program...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  rumor true time arrived codeup officially open...  \n",
       "1  dimitri antoniou maggie giust data science big...  \n",
       "2  dimitri antoniou week ago codeup launched imme...  \n",
       "3  sa tech job fair third biannual san antonio te...  \n",
       "4  competitor bootcamps closing model danger prog...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(original, 'content', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e381822",
   "metadata": {},
   "source": [
    "#### 9.) Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "     - Lemmatized\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "    - Lemmatized\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "    - Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe710c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
